#from http://stackoverflow.com/questions/15532810/reading-40-gb-csv-file-into-r-using-bigmemory
fsample <-
    function(fname, n, seed, header=FALSE, ..., reader = read.table)
    {
        set.seed(seed)
        con <- file(fname, open="r")
        hdr <- if (header) {
            readLines(con, 1L)
        } else character()
        
        buf <- readLines(con, n)
        n_tot <- length(buf)
        
        repeat {
            txt <- readLines(con, n)
            if ((n_txt <- length(txt)) == 0L)
                break
            
            n_tot <- n_tot + n_txt
            n_keep <- rbinom(1, n_txt, n_txt / n_tot)
            if (n_keep == 0L)
                next
            
            keep <- sample(n_txt, n_keep)
            drop <- sample(n, n_keep)
            buf[drop] <- txt[keep]
        }
        
        reader(textConnection(c(hdr, buf)), header=header, ...)
    }
#fsample("Data.tsv", 1000, 1)

dat2<-fsample("Data.tsv", 100000, 1, header=TRUE)
